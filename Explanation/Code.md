# ุชูุถุญุงุช ฺฉุฏ ุงูฺฏูุฑุชู SVM 

##  ุจุฎุด 1: ูุงุฑุฏ ฺฉุฑุฏู ฺฉุชุงุจุฎุงููโูุง
```
# ============================================================================
# COMPLETE SVM IMPLEMENTATION 
# ============================================================================

# Required libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import (accuracy_score, precision_score, recall_score, 
                             f1_score, confusion_matrix, classification_report,
                             roc_curve, roc_auc_score, precision_recall_curve,
                             average_precision_score)
from sklearn.inspection import permutation_importance
import warnings
warnings.filterwarnings('ignore')

# Display settings
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")
```
pandas/numpy: ุจุฑุง ูุฏุฑุช ู ูพุฑุฏุงุฒุด ุฏุงุฏูโูุง

matplotlib/seaborn: ุจุฑุง ูุตูุฑุณุงุฒ ูุชุงุฌ

scikit-learn: ุจุฑุง ูพุงุฏูโุณุงุฒ ุงูฺฏูุฑุชูโูุง ุงุฏฺฏุฑ ูุงุดู

GridSearchCV: ุจุฑุง ุจูููโุณุงุฒ ุฎูุฏฺฉุงุฑ ูพุงุฑุงูุชุฑูุง

SVC: ุจุฑุง ูพุงุฏูโุณุงุฒ Support Vector Classifier

Evaluation: ุฏูุชุ precisionุ recallุ F1-score ู ุฏฺฏุฑ ูุชุฑฺฉโูุง

## ุจุฎุด 2: ุจุงุฑฺฏุฐุงุฑ ุฏุงุฏู

```
# ============================================================================
#  LOAD DATA
# ============================================================================

print("="*60)
print("SVM FOR DIABETES PREDICTION")
print("="*60)

df = pd.read_csv('diabetes.csv')

print("\n Data Information:")
print(f"Data size: {df.shape}")
print(f"\nClass distribution:\n{df['Outcome'].value_counts()}")
print(f"\nPositive class percentage: {(df['Outcome'].mean()*100):.1f}%")
```
## output:
```
============================================================
SVM FOR DIABETES PREDICTION
============================================================

 Data Information:
Data size: (768, 9)

Class distribution:
Outcome
0    500
1    268
Name: count, dtype: int64

Positive class percentage: 34.9%
```

ุจุงุฑฺฏุฐุงุฑ ุฏุงุฏูโูุง ุฏุงุจุช ุงุฒ ูุงู CSV

ููุงุด ุงุจุนุงุฏ ุฏุงุฏู (768 ูููููุ 9 ูฺฺฏ)

ููุงุด ุชูุฒุน ฺฉูุงุณโูุง:

ฺฉูุงุณ 0 (ุจุฏูู ุฏุงุจุช): 500 ููููู (65.1%)

ฺฉูุงุณ 1 (ุฏุงุจุช): 268 ููููู (34.9%)

ุฏุงุฏู ูุงูุชูุงุฒู ุงุณุช (Imbalanced Data)

## ุจุฎุด 3: ูพุดโูพุฑุฏุงุฒุด ุฏุงุฏู

```
# ============================================================================
#  DATA PREPROCESSING
# ============================================================================

print("\n" + "="*60)
print("DATA PREPROCESSING")
print("="*60)

zero_columns = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
for col in zero_columns:
    df[col] = df[col].replace(0, df[col].median())

print("โ Zero values replaced with median")
```
ุดูุงุณุง ุณุชููโูุง ูุดฺฉูโุฏุงุฑ: ููุงุฏุฑ ุตูุฑ ุฏุฑ ุงู ุณุชููโูุง ุบุฑููุทู ูุณุชูุฏ

ุฌุงฺฏุฒู ุจุง ูุงูู: ููุงุฏุฑ ุตูุฑ ุจุง ูุงูู ูุฑ ุณุชูู ุฌุงฺฏุฒู ูโุดููุฏ

ุณุชููโูุง ูพุฑุฏุงุฒุด ุดุฏู:

Glucose (ฺฏููฺฉุฒ)

BloodPressure (ูุดุงุฑ ุฎูู)

SkinThickness (ุถุฎุงูุช ูพูุณุช)

Insulin (ุงูุณููู)

BMI (ุดุงุฎุต ุชูุฏู ุจุฏู)

## ุจุฎุด 4: ุชูุณู ุฏุงุฏู

```
# ============================================================================
#  DATA SPLITTING
# ============================================================================

X = df.drop('Outcome', axis=1)
y = df['Outcome']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nโ Train set: {X_train.shape}")
print(f"โ Test set: {X_test.shape}")
```
## output:
```

โ Train set: (614, 8)
โ Test set: (154, 8)
```
ุฌุฏุงุณุงุฒ ูฺฺฏโูุง ู ุจุฑฺุณุจ:

X: ููู ูฺฺฏโูุง ุจู ุฌุฒ Outcome

y: ุณุชูู Outcome (ุจุฑฺุณุจ 0 ุง 1)

ุชูุณู ุฏุงุฏู:

80% ุจุฑุง ุขููุฒุด (614 ููููู)

20% ุจุฑุง ุขุฒููู (154 ููููู)

stratify=y: ุญูุธ ูุณุจุช ฺฉูุงุณโูุง ุฏุฑ ูุฑ ุจุฎุด

random_state=42: ุจุฑุง ุชฺฉุฑุงุฑูพุฐุฑ ูุชุงุฌ

## ุจุฎุด 5: ุงุณุชุงูุฏุงุฑุฏุณุงุฒ ูฺฺฏโูุง

```
# ============================================================================
#  FEATURE SCALING
# ============================================================================

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("โ Features scaled")
```
StandardScaler: ุงุณุชุงูุฏุงุฑุฏุณุงุฒ ูฺฺฏโูุง ุจู ูุงูฺฏู 0 ู ุงูุญุฑุงู ูุนุงุฑ 1

fit_transform: ุฑู ุฏุงุฏู ุขููุฒุด ูุญุงุณุจู ูพุงุฑุงูุชุฑูุง + ุชุจุฏู

transform: ุฑู ุฏุงุฏู ุขุฒููู ููุท ุชุจุฏู ุจุง ูพุงุฑุงูุชุฑูุง ุขููุฒุด

ุฏูู ุงุณุชุงูุฏุงุฑุฏุณุงุฒ: SVM ุจู ููุงุณ ูฺฺฏโูุง ุญุณุงุณ ุงุณุช.

##  ุจุฎุด 6: ุขููุฒุด ูุฏู SVM ุจุง GridSearchCV
```
# ============================================================================
#  SVM MODEL TRAINING
# ============================================================================

print("\n" + "="*60)
print("TRAINING SVM MODEL")
print("="*60)

param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': ['scale', 'auto', 0.1, 0.01],
    'kernel': ['linear', 'rbf']
}

svm = GridSearchCV(
    SVC(random_state=42, probability=True, class_weight='balanced'),
    param_grid,
    cv=5,
    scoring='f1',
    n_jobs=-1,
    verbose=0
)

svm.fit(X_train_scaled, y_train)

print(f"โ Best parameters: {svm.best_params_}")
print(f"โ Best CV score: {svm.best_score_:.3f}")

best_svm = svm.best_estimator
```
## output:
```

============================================================
TRAINING SVM MODEL
============================================================
โ Best parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}
โ Best CV score: 0.675
```
Grid Search: ุฌุณุชุฌู ุจูุชุฑู ุชุฑฺฉุจ ูพุงุฑุงูุชุฑูุง

ูพุงุฑุงูุชุฑูุง ุฌุณุชุฌู:

C: [0.1, 1, 10, 100] - ูพุงุฑุงูุชุฑ ุฌุฑูู

gamma: ['scale', 'auto', 0.1, 0.01] - ูพุงุฑุงูุชุฑ ฺฉุฑูู RBF

kernel: ['linear', 'rbf'] - ููุน ฺฉุฑูู

ุชูุธูุงุช GridSearchCV:

cv=5: ุงุนุชุจุงุฑุณูุฌ ูุชูุงุจู ต-ุชุง

scoring='f1': ุงุณุชูุงุฏู ุงุฒ F1-score ุจุฑุง ุงุฑุฒุงุจ

n_jobs=-1: ุงุณุชูุงุฏู ุงุฒ ุชูุงู ูุณุชูโูุง CPU

class_weight='balanced': ูุฏุฑุช ุนุฏู ุชูุงุฒู ฺฉูุงุณ

ูุชุงุฌ:

ุจูุชุฑู ูพุงุฑุงูุชุฑูุง: C=1, gamma='scale', kernel='rbf'

ุจูุชุฑู ุงูุชุงุฒ: 0.675

## ุจุฎุด 7: ูพุดโุจู
```
# ============================================================================
#  PREDICTIONS
# ============================================================================

y_pred = best_svm.predict(X_test_scaled)
y_pred_proba = best_svm.predict_proba(X_test_scaled)[:, 1]
```
d: ูพุดโุจู ฺฉูุงุณ (0 ุง 1)

y_pred_proba: ุงุญุชูุงู ุชุนูู ุจู ฺฉูุงุณ ูุซุจุช (ฺฉูุงุณ 1)

[:, 1]: ููุท ุณุชูู ุฏูู ฺฉู ูุฑุจูุท ุจู ฺฉูุงุณ ูุซุจุช ุงุณุช

## ุจุฎุด 8: ุงุฑุฒุงุจ ุฌุงูุน ูุฏู

```
# ============================================================================
#  COMPREHENSIVE EVALUATION
# ============================================================================

print("\n" + "="*50)
print(" COMPREHENSIVE SVM MODEL EVALUATION")
print("="*50)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"\n Main Metrics:")
print(f" Accuracy: {accuracy:.3f}")
print(f" Precision: {precision:.3f}")
print(f" Recall: {recall:.3f}")
print(f" F1-Score: {f1:.3f}")

print(f"\n Complete Classification Report:")
print(classification_report(
    y_test, y_pred, 
    target_names=['No Diabetes', 'Has Diabetes'],
    digits=3
))

cm = confusion_matrix(y_test, y_pred)
tn, fp, fn, tp = cm.ravel()

print(f"\n Confusion Matrix Details:")
print(f"True Positive (TP): {tp}")
print(f"True Negative (TN): {tn}")
print(f"False Positive (FP): {fp}")
print(f"False Negative (FN): {fn}")

specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
npv = tn / (tn + fn) if (tn + fn) > 0 else 0

print(f"\n Additional Metrics:")
print(f"Specificity: {specificity:.3f}")
print(f"Negative Predictive Value (NPV): {npv:.3f}")
```
## output:
```

==================================================
 COMPREHENSIVE SVM MODEL EVALUATION
==================================================

 Main Metrics:
 Accuracy: 0.753
 Precision: 0.618
 Recall: 0.778
 F1-Score: 0.689

 Complete Classification Report:
              precision    recall  f1-score   support

 No Diabetes      0.860     0.740     0.796       100
Has Diabetes      0.618     0.778     0.689        54

    accuracy                          0.753       154
   macro avg      0.739     0.759     0.742       154
weighted avg      0.775     0.753     0.758       154


 Confusion Matrix Details:
True Positive (TP): 42
True Negative (TN): 74
False Positive (FP): 26
False Negative (FN): 12

 Additional Metrics:
Specificity: 0.740
Negative Predictive Value (NPV): 0.860
```
ูุชุฑฺฉโูุง ุงุตู:

Accuracy: 0.753

Precision: 0.618 (ูุฑุฎ ูุซุจุช ูุงูุน)

Recall: 0.778 (ุญุณุงุณุช ูุฏู)

F1-Score: 0.689 (ูุงูฺฏู ูุงุฑูููฺฉ precision ู recall)

ูุงุชุฑุณ ุฏุฑููโุฑุฎุชฺฏ:

TP: 42 (ุฏุงุจุช ฺฉู ุฏุฑุณุช ุชุดุฎุต ุฏุงุฏู ุดุฏ)

TN: 74 (ุณุงูู ฺฉู ุฏุฑุณุช ุชุดุฎุต ุฏุงุฏู ุดุฏ)

FP: 26 (ุณุงูู ฺฉู ุงุดุชุจุงู ุฏุงุจุช ุชุดุฎุต ุฏุงุฏู ุดุฏ)

FN: 12 (ุฏุงุจุช ฺฉู ุชุดุฎุต ุฏุงุฏู ูุดุฏ)

ูุชุฑฺฉโูุง ุงุถุงู:

Specificity: 0.740 (ูุฑุฎ ููู ูุงูุน)

NPV: 0.860 (ุงุฑุฒุด ูพุดโุจู ููู)

## ุจุฎุด 9 : ูพูุงุช ูุง ุงุฑุฒุงุจ

<img width="1189" height="1025" alt="image" src="https://github.com/user-attachments/assets/8f7ade47-21a7-4b15-ad0b-f0375ba3bfeb" />

##  1. ูุงุชุฑุณ ุฏุฑููโุฑุฎุชฺฏ (Confusion Matrix)
- True Negative (TN) = 74 โ ููุงุฑุฏ ฺฉู ูุงูุนุงู ุฏุงุจุช ูุฏุงุดุชูุฏ ู ูุฏู ุฏุฑุณุช ุชุดุฎุต ุฏุงุฏู.
- False Positive (FP) = 26 โ ููุงุฑุฏ ฺฉู ุฏุงุจุช ูุฏุงุดุชูุฏุ ุงูุง ูุฏู ุงุดุชุจุงู ฺฏูุชู "ุฏุงุฑุฏ".
- False Negative (FN) = 12 โ ููุงุฑุฏ ฺฉู ุฏุงุจุช ุฏุงุดุชูุฏุ ุงูุง ูุฏู ุงุดุชุจุงู ฺฏูุชู "ูุฏุงุฑุฏ".
- True Positive (TP) = 42 โ ููุงุฑุฏ ฺฉู ุฏุงุจุช ุฏุงุดุชูุฏ ู ูุฏู ุฏุฑุณุช ุชุดุฎุต ุฏุงุฏู.

## 2. ูููุฏุงุฑ ูุนุงุฑูุง ุนููฺฉุฑุฏ (Accuracy, Precision, Recall, F1-Score)
- Accuracy = 0.753 โ 75.3% ุงุฒ ุชูุงู ูููููโูุง ุฏุฑุณุช ุทุจููโุจูุฏ ุดุฏูโุงูุฏ.
- Precision = 0.618 โ ููุช ูุฏู ูโฺฏูุฏ "ุฏุงุฑุฏ"ุ 61.8% ุงุฒ ุงู ูพุดโุจูโูุง ุฏุฑุณุช ูุณุชูุฏ.
- Recall = 0.778 โ ุงุฒ ุชูุงู ุงูุฑุงุฏ ูุงูุน ุจุง ุฏุงุจุชุ ูุฏู 77.8% ุฑุง ุชุดุฎุต ุฏุงุฏู.
- F1-Score = 0.689 โ ูุงูฺฏู ูุงุฑูููฺฉ precision ู recall โ ูุดุงูโุฏููุฏู ุชุนุงุฏู ุจู ุฏูุช ู ุญุณุงุณุช.

## 3. ููุญู ROC ู AUC

- AUC = 0.810 โ ูุดุงูโุฏููุฏู ุนููฺฉุฑุฏ ุฎูุจ ูุฏู ุฏุฑ ุชูุงุฒ ุจู ฺฉูุงุณโูุง ุงุณุช.
- AUC > 0.8 = ุฎูุจ
- AUC > 0.9 = ุนุงู
 ุงู ุนุฏุฏ ูุดุงู ูโุฏูุฏ ูุฏู ุฏุฑ ููุงุณู ุจุง ฺฉ ุญุฏุณ ุชุตุงุฏู (ุฎุท ุฒุฑุฏ)ุ ุนููฺฉุฑุฏ ูุงุจู ูุจูู ุฏุงุฑุฏ.

## 4. ููุญู Precision-Recall ู AP

AP (Average Precision) = 0.668 โ ูุนุงุฑ ุจุฑุง ุงุฑุฒุงุจ ูุฏูโูุง ฺฉู ฺฉูุงุณโูุง ูุงูุชุนุงุฏู ูุณุชูุฏ (ูุซู ุงูุฌุง ฺฉู ุงุญุชูุงูุงู ุงูุฑุงุฏ ุจุฏูู ุฏุงุจุช ุจุดุชุฑ ูุณุชูุฏ).
ููุญู ูุดุงู ูโุฏูุฏ ฺฉู ุจุง ุงูุฒุงุด recallุ precision ฺฉุงูุด ูพุฏุง ูโฺฉูุฏ โ ฺฉู ุทุจุน ุงุณุช.

 ุงู ูุดุงู ูโุฏูุฏ ฺฉู ูุฏู ุฏุฑ ุดุฑุงุท ฺฉู ฺฉูุงุณ ูุซุจุช ฺฉูโุชุนุฏุงุฏ ุงุณุช (ุจูุงุฑุงู)ุ ุนููฺฉุฑุฏุด ฺฉู ุถุนูโุชุฑ ุงุฒ AUC ุงุณุช. 

 ููุงุท ููุช ูุฏู:

Accuracy ู AUC ุฎูุจ ุฏุงุฑุฏ (75% ู 81%).
Recall ุจุงูุง โ ุนู ุจุดุชุฑ ุจูุงุฑุงู ุฑุง ุชุดุฎุต ูโุฏูุฏ (ููู ุฏุฑ ูพุฒุดฺฉ!).
 ููุงุท ุถุนู:

Precision ูพุงู โ ูุฏู ุฒุงุฏ ุงุดุชุจุงู ูุซุจุช ูโุฏูุฏ (ุงูุฑุงุฏ ุณุงูู ุฑุง ุจูุงุฑ ูโฺฏุฑุฏ).
F1-Score ูุชูุณุท โ ูุดุงูโุฏููุฏู ุนุฏู ุชุนุงุฏู ุจู ุฏูุช ู ุญุณุงุณุช.


## ุจุฎุด 10 ูพูุงุช ุงููุช ูฺฺฏ ูุง - FEATURE IMPORTANCE
```
# ============================================================================
#  Feature Importance 
# ============================================================================

print("\n" + "="*60)
print("MODEL INTERPRETATION - FEATURE IMPORTANCE")
print("="*60)

plt.figure(figsize=(10, 6))

if best_svm.kernel == 'linear':
    coefficients = pd.DataFrame({
        'Feature': X.columns,
        'Coefficient': best_svm.coef_[0],
        'Abs_Coefficient': np.abs(best_svm.coef_[0])
    }).sort_values('Abs_Coefficient', ascending=False)

    print(coefficients.drop('Abs_Coefficient', axis=1).to_string(index=False))
    plt.barh(coefficients['Feature'], coefficients['Coefficient'])
else:
    perm_importance = permutation_importance(
        best_svm, X_test_scaled, y_test, n_repeats=10, random_state=42
    )
    feature_importance = pd.DataFrame({
        'Feature': X.columns,
        'Importance': perm_importance.importances_mean
    }).sort_values('Importance', ascending=False)

    print(feature_importance.to_string(index=False))
    plt.barh(feature_importance['Feature'], feature_importance['Importance'])

plt.tight_layout()
plt.show()
```
## output:

<img width="990" height="590" alt="image" src="https://github.com/user-attachments/assets/ded88789-ee5f-490f-bd06-cbe14cb4db2f" />


Glucose (ฺฏููฺฉุฒ) โ ุจุงูุงุชุฑู ุงููุช (~0.09)
โ ุงู ูุดุงู ูโุฏูุฏ ฺฉู ุณุทุญ ฺฏููฺฉุฒ ุฎูู ููโุชุฑู ูพุดโุจูโฺฉููุฏู ุจุฑุง ุชุดุฎุต ุฏุงุจุช ุงุณุช โ ฺฉู ฺฉุงููุงู ููุทู ู ูุทุงุจู ุจุง ุฏุงูุด ูพุฒุดฺฉ ุงุณุช.

Age (ุณู) โ ุงููุช ~0.05
โ ุณู ุนุงูู ุฎุทุฑ ููู ุฏุฑ ุฏุงุจุช ููุน 2 ุงุณุช โ ูุฏู ุงู ุฑุง ุฏุฑฺฉ ฺฉุฑุฏู.

BMI (ุดุงุฎุต ุชูุฏู ุจุฏู) โ ุงููุช ~0.035
โ ฺุงู ู ุงุถุงูู ูุฒู ุงุฒ ุนูุงูู ุงุตู ุฏุงุจุช ูุณุชูุฏ.

DiabetesPedigreeFunction โ ุงููุช ~0.03
โ ุงู ูฺฺฏ ูุดุงูโุฏููุฏู ุณุงุจูู ุฎุงููุงุฏฺฏ ุฏุงุจุช ุงุณุช โ ูุฏู ุขู ุฑุง ููู ุชุดุฎุต ุฏุงุฏู.

Pregnancies (ุจุงุฑุฏุงุฑโูุง) โ ุงููุช ~0.03
โ ุชุนุฏุงุฏ ุจุงุฑุฏุงุฑโูุง (ุจู ุฎุตูุต ุฏุฑ ุฒูุงู) ุจุง ุฏุงุจุช ุจุงุฑุฏุงุฑ ู ุจุนุฏ ุงุฒ ุขู ูุฑุชุจุท ุงุณุช.

Insulin (ุงูุณููู) โ ุงููุช ~0.01
โ๏ธ ฺฉูุชุฑ ุงุฒ ุงูุชุธุงุฑ โ ููฺฉู ุงุณุช ุฏุงุฏูโูุง ุงูุณููู ููุณุงู ุฒุงุฏ ุฏุงุดุชู ุจุงุดูุฏ ุง ููุงุฏุฑ ุฒุงุฏ NaN/ุตูุฑ ุฏุงุดุชู ุจุงุดูุฏ.

BloodPressure (ูุดุงุฑ ุฎูู) โ ุงููุช ุจุณุงุฑ ฺฉู
โ ููฺฉู ุงุณุช ุงู ูฺฺฏ ุฏุฑ ุฏุงุฏูโูุง ููุจุณุชฺฏ ุถุนู ุจุง ูุฏู ุฏุงุดุชู ุจุงุดุฏ ุง ููุงุฏุฑ ุขู ูุณุจุชุงู ุซุงุจุช ุจุงุดูุฏ.

SkinThickness (ุถุฎุงูุช ูพูุณุช) โ ฺฉูุชุฑู ุงููุช (~0.002)
โ ุงู ูฺฺฏ ุชูุฑุจุงู ูฺ ููุด ุฏุฑ ูพุดโุจู ูุฏุงุฑุฏ โ ูโุชูุงู ุขู ุฑุง ุญุฐู ฺฉู ุง ุจุฑุฑุณ ฺฉู ฺฉู ุขุง ุฏุงุฏูโูุงุด ูุงุณุงูู ูุณุชูุฏ ุง ุฎุฑ.


## ุจุฎุด 11 ุชุญูู ุขุณุชุงูู - threshold

```
# ============================================================================
#   Threshold Analysis 
# ============================================================================

print("\n" + "="*60)
print("THRESHOLD ANALYSIS")
print("="*60)

thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]
print("\nThreshold | Precision | Recall | F1-Score")
print("-" * 40)

precisions = []
recalls = []
f1_scores = []

for thresh in thresholds:
    y_pred_thresh = (y_pred_proba >= thresh).astype(int)
    p = precision_score(y_test, y_pred_thresh, zero_division=0)
    r = recall_score(y_test, y_pred_thresh)
    f = f1_score(y_test, y_pred_thresh)
    
    precisions.append(p)
    recalls.append(r)
    f1_scores.append(f)
    
    print(f"{thresh:.1f}       | {p:.3f}     | {r:.3f}  | {f:.3f}")

plt.figure(figsize=(10, 6))
plt.plot(thresholds, precisions, lw=2, label='Precision', marker='o')
plt.plot(thresholds, recalls, lw=2, label='Recall', marker='s')
plt.plot(thresholds, f1_scores, lw=3, label='F1-Score', marker='^')

plt.xlabel('Threshold', fontsize=12)
plt.ylabel('Score', fontsize=12)
plt.title('SVM - Threshold Analysis', fontsize=14, fontweight='bold')
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3)

optimal_idx = np.argmax(f1_scores)
optimal_threshold = thresholds[optimal_idx]
plt.axvline(x=optimal_threshold, linestyle='--', alpha=0.7)
plt.text(optimal_threshold + 0.02, 0.1,
         f'Optimal: {optimal_threshold:.2f}',
         fontsize=11, fontweight='bold')

plt.tight_layout()
plt.show()
```
## output:

<img width="989" height="583" alt="image" src="https://github.com/user-attachments/assets/5b7a2086-5301-45f4-ba82-e0bf812efe28" />

```
============================================================
THRESHOLD ANALYSIS
============================================================

Threshold | Precision | Recall | F1-Score
----------------------------------------
0.3       | 0.575     | 0.852  | 0.687
0.4       | 0.618     | 0.778  | 0.689
0.5       | 0.633     | 0.574  | 0.602
0.6       | 0.657     | 0.426  | 0.517
0.7       | 0.714     | 0.278  | 0.400
```

### ูุญูุฑูุง ูููุฏุงุฑ:

- ูุญูุฑ ุงูู (X): ููุฏุงุฑ ุขุณุชุงูู (Threshold) ุงุฒ 0.30 ุชุง 0.70
- ูุญูุฑ ุนููุฏ (Y): ููุฏุงุฑ ูุนุงุฑูุง ุนููฺฉุฑุฏ (ุงุฒ 0.25 ุชุง 0.85)
  
### ุฎุทูุท:

- ูุฑูุฒ (Precision): ุจุง ุงูุฒุงุด ุขุณุชุงููุ precision ุงูุฒุงุด ูพุฏุง ูโฺฉูุฏ.
- ุฒุฑุฏ (Recall): ุจุง ุงูุฒุงุด ุขุณุชุงููุ recall ฺฉุงูุด ูโุงุจุฏ.
- ุณุจุฒ (F1-Score): ูุงูฺฏู ูุงุฑูููฺฉ precision ู recall โ ุงุจุชุฏุง ุซุงุจุช ุงุณุชุ ุณูพุณ ฺฉุงูุด ูโุงุจุฏ.
- 
### ุฎุท ููุทูโฺู ูุฑูุฒ:

ูุดุงูโุฏููุฏู ุขุณุชุงูู ุจููู (Optimal Threshold = 0.40) ุงุณุช.
ุฏุฑ ุงู ููุทูุ F1-Score ุจุดุชุฑู ููุฏุงุฑ ุฎูุฏ ุฑุง ุฏุงุฑุฏ (ุญุฏูุฏ 0.69).


## ุฎุด 11 ูุฒุน ุงุญุชูุงู ูพุดโุจู ุดุฏู ุชูุณุท ูุฏู SVM ุฑุง ุจุฑ ุงุณุงุณ ฺฉูุงุณโูุง

```
# ============================================================================
#   Probability Distribution
# ============================================================================

print("\n" + "="*60)
print("PROBABILITY DISTRIBUTION ANALYSIS")
print("="*60)

plt.figure(figsize=(12, 5))

# Histogram
plt.subplot(1, 2, 1)
bins = np.linspace(0, 1, 21)
plt.hist(y_pred_proba[y_test == 0], bins=bins, alpha=0.7,
         label='No Diabetes', density=True)
plt.hist(y_pred_proba[y_test == 1], bins=bins, alpha=0.7,
         label='Has Diabetes', density=True)
plt.axvline(x=0.5, linestyle='--', linewidth=2, label='Threshold = 0.5')

plt.xlabel('Predicted Probability')
plt.ylabel('Density')
plt.title('Probability Distribution by Class', fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)

# Box Plot
plt.subplot(1, 2, 2)
data_to_plot = [y_pred_proba[y_test == 0], y_pred_proba[y_test == 1]]
plt.boxplot(data_to_plot, patch_artist=True,
            labels=['No Diabetes', 'Has Diabetes'])

plt.ylabel('Predicted Probability')
plt.title('Probability Distribution - Box Plot', fontweight='bold')
plt.grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.show()
```

## output:

<img width="1189" height="489" alt="image" src="https://github.com/user-attachments/assets/1196c6d4-136b-4ebc-8b13-ad43182845ab" />

 1. ูููุฏุงุฑ ุณูุช ฺูพ: Probability Distribution by Class (ูุณุชูฺฏุฑุงู ฺฺฏุงู)

### ูุญูุฑูุง ูููุฏุงุฑ:

ูุญูุฑ ุงูู (X): ุงุญุชูุงู ูพุดโุจู ุดุฏู ุจุฑุง ฺฉูุงุณ "Has Diabetes" (ุงุฒ 0 ุชุง 1)
ูุญูุฑ ุนููุฏ (Y): ฺฺฏุงู (Density) โ ูุดุงูโุฏููุฏู ุชุนุฏุงุฏ ูููููโูุง ุฏุฑ ูุฑ ุจุงุฒู ุงุญุชูุงู

### ุฑูฺฏโูุง:

ุตูุฑุช: ูููููโูุง ูุงูุน ุจุฏูู ุฏุงุจุช (No Diabetes)
ุฒุฑุฏ: ูููููโูุง ูุงูุน ุจุง ุฏุงุจุช (Has Diabetes)
ุฎุท ฺู ุตูุฑุช: ุขุณุชุงูู 0.5 โ ูุฑุฒ ฺฉู ูุฏู ุจุฑ ุงุณุงุณ ุขู ุชุตูู ูโฺฏุฑุฏ.

### ุจุฑุง ฺฉูุงุณ Has Diabetes (ุฒุฑุฏ):
ุงฺฉุซุฑ ูููููโูุง ุฏุฑ ุงุญุชูุงู ุจุงูุงุชุฑ ุงุฒ 0.5 ูุฑุงุฑ ุฏุงุฑูุฏ โ ุนู ูุฏู ุจุฑุง ุงูุฑุงุฏ ูุงูุน ุจุง ุฏุงุจุชุ ุงุญุชูุงู ุจุงูุง ูพุดโุจู ูโฺฉูุฏ.
ฺฉ ูพฺฉ ูู ุฏุฑ ุญุฏูุฏ 0.8โ0.9 ุฏุฏู ูโุดูุฏ โ ุนู ูุฏู ุฎูุจ ุฏุฑ ุชุดุฎุต ุจูุงุฑุงู ุงุณุช.
ุงูุง ฺูุฏ ููููู ุฏุฑ ุฒุฑ 0.5 ูู ูุณุชูุฏ โ ุงูโูุง False Negatives ูุณุชูุฏ (ุจูุงุฑุงู ฺฉู ูุฏู ุงุดุชุจุงู ุณุงูู ุชุดุฎุต ุฏุงุฏู).
### ุจุฑุง ฺฉูุงุณ No Diabetes (ุตูุฑุช):
ุจุฎุด ุฒุงุฏ ุงุฒ ูููููโูุง ุฏุฑ ุงุญุชูุงู ูพุงูโุชุฑ ุงุฒ 0.5 ูุณุชูุฏ โ ุนู ูุฏู ุงูุฑุงุฏ ุณุงูู ุฑุง ุฏุฑุณุช ุชุดุฎุต ูโุฏูุฏ.
ุงูุง ุชุนุฏุงุฏ ูุงุจู ุชูุฌู ุงุฒ ุงูุฑุงุฏ ุณุงูู ุฏุฑ ุงุญุชูุงู ุจุงูุงุชุฑ ุงุฒ 0.5 ูุฑุงุฑ ุฏุงุฑูุฏ โ ุงูโูุง False Positives ูุณุชูุฏ (ุงูุฑุงุฏ ุณุงูู ฺฉู ูุฏู ุงุดุชุจุงู ุจูุงุฑ ุชุดุฎุต ุฏุงุฏู).
ุงู ูุดฺฉู ููุฌุฑ ุจู Precision ูพุงู ูโุดูุฏ โ ฺูู ููุช ูุฏู ูโฺฏูุฏ "ุฏุงุฑุฏ"ุ ุฏุฑ ูุงูุน ุชุนุฏุงุฏ ุงุฒ ุขูโูุง ุณุงูู ูุณุชูุฏ.

2. ูููุฏุงุฑ ุณูุช ุฑุงุณุช: Probability Distribution - Box Plot

### ูุญูุฑูุง ูููุฏุงุฑ:

ูุญูุฑ ุงูู (X): ฺฉูุงุณโูุง (No Diabetes ู Has Diabetes)
ูุญูุฑ ุนููุฏ (Y): ุงุญุชูุงู ูพุดโุจู ุดุฏู ุจุฑุง ฺฉูุงุณ "Has Diabetes"

### ุนูุงุตุฑ ุฌุนุจู:

ุฎุท ูุณุท ุฌุนุจู: ูุงูู (Median) ุงุญุชูุงู
ุฌุนุจู: ฺุงุฑฺฉ ุงูู ุชุง ุณูู (IQR)
ุฎุทูุท (Whiskers): ุฏุงููู ุฏุงุฏูโูุง (ุจุฏูู ุข์ูุงุฑ)
ููุทูโูุง ุฌุฏุง ุดุฏู: ุข์ูุงุฑูุง (ุงฺฏุฑ ูุฌูุฏ ุฏุงุดุชู ุจุงุดูุฏ)

 ## ุจุฑุง Has Diabetes (ุฌุนุจู ุตูุฑุช ุฑุงุณุช):
ูุงูู โ 0.5 โ ุนู ูู ุงุฒ ุจูุงุฑุงู ุงุญุชูุงู ุจุงูุงุชุฑ ุงุฒ 0.5 ุฏุงุฑูุฏ.
ฺุงุฑฺฉ ุณูู (Q3) โ 0.75 โ ุนู 75% ุงุฒ ุจูุงุฑุงู ุงุญุชูุงู ุจุงูุงุชุฑ ุงุฒ 0.75 ุฏุงุฑูุฏ โ ุฎูุจ!
ุญุฏุงูู โ 0.1 โ ุนู ุจุนุถ ุจูุงุฑุงู ุงุญุชูุงู ุจุณุงุฑ ูพุงู ุฏุฑุงูุช ฺฉุฑุฏูโุงูุฏ โ ุงูโูุง False Negatives ูุณุชูุฏ.

### ุจุฑุง No Diabetes (ุฌุนุจู ุตูุฑุช ฺูพ):
ูุงูู โ 0.15 โ ุนู ูู ุงุฒ ุงูุฑุงุฏ ุณุงูู ุงุญุชูุงู ูพุงู ุฏุงุฑูุฏ โ ุฎูุจ.
ฺุงุฑฺฉ ุณูู (Q3) โ 0.4 โ ุนู 75% ุงุฒ ุงูุฑุงุฏ ุณุงูู ุงุญุชูุงู ฺฉูุชุฑ ุงุฒ 0.4 ุฏุงุฑูุฏ โ ุฎูุจ.
ุญุฏุงฺฉุซุฑ โ 0.8 โ ุนู ุจุนุถ ุงูุฑุงุฏ ุณุงูู ุงุญุชูุงู ุจุณุงุฑ ุจุงูุง (ุญุช ุจุงูุงุชุฑ ุงุฒ 0.8) ุฏุฑุงูุช ฺฉุฑุฏูโุงูุฏ โ ุงูโูุง False Positives ูุณุชูุฏ.

ุงู ุฌุนุจูโูุง ูุดุงู ูโุฏููุฏ ฺฉู ุชูุฒุน ุงุญุชูุงูโูุง ุจุฑุง ุฏู ฺฉูุงุณ ูููพูุดุงู ุฏุงุฑุฏ โ ุนู ูุฏู ููโุชูุงูุฏ ุจู ุทูุฑ ฺฉุงูู ุงู ุฏู ฺฉูุงุณ ุฑุง ุงุฒ ูู ุฌุฏุง ฺฉูุฏ. ุงู ููโูพูุดุงู ุฏูู ุงุตู ุฎุทุงูุง ุทุจููโุจูุฏ ุงุณุช.


๐น ููุงุท ููุช:
ูุฏู ุจุฑุง ุจุดุชุฑ ุจูุงุฑุงู ุงุญุชูุงู ุจุงูุง ูพุดโุจู ูโฺฉูุฏ (ูุงูู 0.5 ู Q3=0.75).
ุจุฑุง ุจุดุชุฑ ุงูุฑุงุฏ ุณุงูู ุงุญุชูุงู ูพุงู ูพุดโุจู ูโฺฉูุฏ (ูุงูู 0.15 ู Q3=0.4).

๐นููุงุท ุถุนู:
ูููพูุดุงู ุชูุฒุน ุงุญุชูุงูโูุง โ ููุฌุฑ ุจู False Positives ู False Negatives ูโุดูุฏ.
ุชุนุฏุงุฏ ูุงุจู ุชูุฌู ุงุฒ ุงูุฑุงุฏ ุณุงูู ุฏุฑ ุงุญุชูุงู ุจุงูุงุชุฑ ุงุฒ 0.5 ูุฑุงุฑ ุฏุงุฑูุฏ โ Precision ูพุงู.
ุชุนุฏุงุฏ ุงุฒ ุจูุงุฑุงู ุฏุฑ ุงุญุชูุงู ูพุงูโุชุฑ ุงุฒ 0.5 ูุฑุงุฑ ุฏุงุฑูุฏ โ Recall ฺฉู ฺฉุงูุด ูโุงุจุฏ.

  ูุชุฌู ููุง:
ุงู ูููุฏุงุฑูุง ูุดุงู ูโุฏููุฏ ฺฉู ูุฏู SVM ุดูุง ุฏุฑ ุชุดุฎุต ุจูุงุฑุงู ุฎูุจ ุนูู ูโฺฉูุฏุ ุงูุง ุฏุฑ ุชุดุฎุต ุงูุฑุงุฏ ุณุงูู ุถุนูโุชุฑ ุงุณุช โ ฺูู ุชูุฒุน ุงุญุชูุงูโูุง ุจุฑุง ุฏู ฺฉูุงุณ ูููพูุดุงู ุฏุงุฑุฏ.
ุจุง ุชูุธู ุขุณุชุงูู ุจู 0.40ุ ูโุชูู ุชุนุงุฏู ุจูุชุฑ ุจู precision ู recall ุงุฌุงุฏ ฺฉู โ ู ุงู ฺฉ ฺฏุงู ุจุณุงุฑ ููู ุจุฑุง ุจูุจูุฏ ุนููฺฉุฑุฏ ูุฏู ุฏุฑ ฺฉุงุฑุจุฑุฏูุง ูพุฒุดฺฉ ุงุณุช.

## ุจุฎุด12 ุชุญูู ุฎุทุง 

```
# ============================================================================
#    Error Analysis
# ============================================================================

print("\n" + "="*60)
print("ERROR ANALYSIS")
print("="*60)

plt.figure(figsize=(8, 6))

error_types = ['False Positives', 'False Negatives',
               'True Positives', 'True Negatives']
error_counts = [fp, fn, tp, tn]

bars = plt.bar(error_types, error_counts,
               edgecolor='black', linewidth=1.5, alpha=0.8)

plt.title('SVM Error Analysis', fontsize=16, fontweight='bold', pad=20)
plt.ylabel('Count', fontsize=12)
plt.grid(True, alpha=0.3, axis='y')

for bar, count in zip(bars, error_counts):
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,
             str(count), ha='center', va='bottom',
             fontsize=11, fontweight='bold')

plt.tight_layout()
plt.show()
```

## output:

<img width="790" height="589" alt="image" src="https://github.com/user-attachments/assets/d4e8c0e3-cb81-4e25-8f8b-f60e0a7a659c" />

## ูุญูุฑูุง ูููุฏุงุฑ:

ูุญูุฑ ุงูู (X): ููุน ุฎุทุง ุง ูพุดโุจู (False Positives, False Negatives, True Positives, True Negatives)
ูุญูุฑ ุนููุฏ (Y): ุชุนุฏุงุฏ ูููููโูุง (Count)

ููุงุฏุฑ:

- False Positives (FP) = 26 โ ุงูุฑุงุฏ ุณุงูู ฺฉู ูุฏู ุงุดุชุจุงู "ุฏุงุฑุฏ ุฏุงุจุช" ุชุดุฎุต ุฏุงุฏู.
- False Negatives (FN) = 12 โ ุงูุฑุงุฏ ุจูุงุฑ ฺฉู ูุฏู ุงุดุชุจุงู "ูุฏุงุฑุฏ ุฏุงุจุช" ุชุดุฎุต ุฏุงุฏู.
- True Positives (TP) = 42 โ ุงูุฑุงุฏ ุจูุงุฑ ฺฉู ูุฏู ุฏุฑุณุช "ุฏุงุฑุฏ ุฏุงุจุช" ุชุดุฎุต ุฏุงุฏู.
- True Negatives (TN) = 74 โ ุงูุฑุงุฏ ุณุงูู ฺฉู ูุฏู ุฏุฑุณุช "ูุฏุงุฑุฏ ุฏุงุจุช" ุชุดุฎุต ุฏุงุฏู.

ุงู ุงุนุฏุงุฏ ุฏููุงู ููุงู ุงุนุฏุงุฏ ูุณุชูุฏ ฺฉู ุฏุฑ ูุงุชุฑุณ ุฏุฑููโุฑุฎุชฺฏ ุฏุฏู โ ูพุณ ุงู ูููุฏุงุฑ ููุท ฺฉ ููุงุด ุจุตุฑ ุงุฒ ููุงู ุฏุงุฏูโูุงุณุชุ ุงูุง ุจุง ุชูุฑฺฉุฒ ุจุฑ ุฎุทุงูุง ูุฏู.


1. False Positives (FP = 26)

ุงูโูุง ุงุดุชุจุงู ูุซุจุช ูุณุชูุฏ โ ุนู ูุฏู ุงูุฑุงุฏ ุณุงูู ุฑุง ุจูุงุฑ ุชุดุฎุต ุฏุงุฏู.
ุฏุฑ ฺฉุงุฑุจุฑุฏูุง ูพุฒุดฺฉุ ุงู ุฎุทุง ููฺฉูู ููุฌุฑ ุจู:
ุงุถุทุฑุงุจ ุบุฑุถุฑูุฑ ุจุฑุง ุจูุงุฑ
ูุฒููโูุง ุงุถุงู ุจุฑุง ุชุณุชโูุง ุชฺฉูู
ุงุดุชุบุงู ุบุฑุถุฑูุฑ ููุงุจุน ูพุฒุดฺฉ

โ๏ธ ุงู ุนุฏุฏ ูุณุจุชุงู ุจุงูุงุณุช โ ู ุนูุช ุงุตู Precision ูพุงู (0.618) ุงุณุช.



2. False Negatives (FN = 12)

ุงูโูุง ุงุดุชุจุงู ููู ูุณุชูุฏ โ ุนู ูุฏู ุงูุฑุงุฏ ุจูุงุฑ ุฑุง ุณุงูู ุชุดุฎุต ุฏุงุฏู.
ุฏุฑ ฺฉุงุฑุจุฑุฏูุง ูพุฒุดฺฉุ ุงู ุฎุทุง ุฎุทุฑูุงฺฉโุชุฑ ุงุณุช โ ฺูู ููฺฉูู ุจุงุนุซ ุชุฃุฎุฑ ุฏุฑ ุฏุฑูุงู ุดูุฏ.
โ ุฎูุดุจุฎุชุงูู ุงู ุนุฏุฏ ฺฉู ุงุณุช (ุชููุง 12 ููุฑุฏ) โ ู ูุดุงูโุฏููุฏู Recall ุจุงูุง (0.778) ุงุณุช.



3. True Positives (TP = 42) ู True Negatives (TN = 74)

ุงูโูุง ูพุดโุจูโูุง ุฏุฑุณุช ูุณุชูุฏ.
ูุฏู ุฏุฑ ุชุดุฎุต ุงูุฑุงุฏ ุณุงูู (TN=74) ุนููฺฉุฑุฏ ุจูุชุฑ ุฏุงุฑุฏ โ ุงูุง ุฏุฑ ุชุดุฎุต ุจูุงุฑุงู (TP=42) ฺฉู ุถุนูโุชุฑ ุงุณุช.



## ุจุฎุด 13 ุชูุณู ฺฉูุงุณ ูุง
 ```
# ============================================================================
#   Class Distribution
# ============================================================================

print("\n" + "="*60)
print("CLASS DISTRIBUTION")
print("="*60)

plt.figure(figsize=(10, 4))

# Train vs Test
plt.subplot(1, 2, 1)
train_counts = y_train.value_counts()
test_counts = y_test.value_counts()

x = np.arange(2)
width = 0.35

plt.bar(x - width/2, train_counts.values, width,
        label='Train', edgecolor='black')
plt.bar(x + width/2, test_counts.values, width,
        label='Test', edgecolor='black')

plt.xlabel('Class')
plt.ylabel('Count')
plt.title('Class Distribution: Train vs Test', fontweight='bold')
plt.xticks(x, ['No Diabetes', 'Has Diabetes'])
plt.legend()
plt.grid(True, alpha=0.3, axis='y')

# Pie chart
plt.subplot(1, 2, 2)
class_counts = df['Outcome'].value_counts()

plt.pie(class_counts,
        labels=['No Diabetes', 'Has Diabetes'],
        autopct='%1.1f%%',
        startangle=90,
        explode=(0.05, 0))

plt.title('Overall Class Distribution', fontweight='bold')

plt.tight_layout()
plt.show()
```
## output:

<img width="954" height="390" alt="image" src="https://github.com/user-attachments/assets/6284e3e8-0f45-4360-971e-07b89d05a396" />

### ุชูุณู ุฏุงุฏูโูุง (Train/Test Split)
ูุณุจุช ฺฉูุงุณโูุง ุฏุฑ Train ู Test ุชูุฑุจุงู ฺฉุณุงู ุงุณุช โ ุนู:
ุฏุฑ Train: ~65% No Diabetes, ~35% Has Diabetes
ุฏุฑ Test: ~67% No Diabetes, ~33% Has Diabetes
ุงู ฺฉ ุชูุณู ุฎูุจ ุงุณุช โ ฺูู ูุฏู ุฑู ฺฉ ุชูุฒุน ูุดุงุจู ุขููุฒุด ุฏุฏู ู ุฑู ฺฉ ุชูุฒุน ูุดุงุจู ุชุณุช ูโุดูุฏ. ุงู ุจุงุนุซ ูโุดูุฏ ฺฉู ูุชุงุฌ ุชุณุช ูุงุจู ุงุนุชูุงุฏ ุจุงุดุฏ.


ูุณู ุฏุงุฏูโูุง ุจู ุฏุฑุณุช ุงูุฌุงู ุดุฏู โ ุนู ูุฌููุนู ุขููุฒุด ู ุขุฒููู ุชูุฒุน ูุดุงุจู ุฏุงุฑูุฏ.
ุงู ูุดุงูโุฏููุฏู ุฑูุด ุตุญุญ ุชูุณู ุฏุงุฏู ุงุณุช โ ู ุจุงุนุซ ูโุดูุฏ ฺฉู ูุชุงุฌ ุชุณุช ูุงุจู ุงุนุชูุงุฏ ุจุงุดุฏ.
ุจุง ุชูุฌู ุจู ูุงูุชุนุงุฏู ุจูุฏู ุฏุงุฏูโูุงุ ูุนุงุฑูุง ูุซู F1-Score ู AUC ุจุฑุง ุงุฑุฒุงุจ ูุฏู ููุงุณุจโุชุฑ ุงุฒ Accuracy ูุณุชูุฏ.


## ุจุฎุด 14 ุฎูุงุตู ุนููฺฉุฑุฏ ููุง ูุฏู

```
# ============================================================================
# FINAL PERFORMANCE SUMMARY TABLE
# ============================================================================

print("\n" + "="*50)
print(" FINAL PERFORMANCE SUMMARY")
print("="*50)

summary_df = pd.DataFrame({
    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score',
               'Specificity', 'NPV', 'ROC-AUC'],
    'Value': [accuracy, precision, recall, f1,
              specificity, npv, roc_auc],
    'Interpretation': [
        'Overall correctness',
        'Correct positive predictions',
        'Ability to find all positives',
        'Balance of Precision and Recall',
        'Ability to identify negatives',
        'Correct negative predictions',
        'Overall classification ability'
    ]
})

print(summary_df.to_string(index=False))


```

## output:
```
==================================================
 FINAL PERFORMANCE SUMMARY
==================================================
     Metric    Value                  Interpretation
   Accuracy 0.753247             Overall correctness
  Precision 0.617647    Correct positive predictions
     Recall 0.777778   Ability to find all positives
   F1-Score 0.688525 Balance of Precision and Recall
Specificity 0.740000   Ability to identify negatives
        NPV 0.860465    Correct negative predictions
    ROC-AUC 0.809630  Overall classification ability
```


## ๐ ุฌุฏูู ุนููฺฉุฑุฏ ููุง โ ุชุญูู ุนูู

| ูุชุฑฺฉ | ููุฏุงุฑ | ุชูุณุฑ ู ุงููุช ุฏุฑ ุชุดุฎุต ุฏุงุจุช |
|-------|--------|-----------------------------|
| **Accuracy** | `0.753` | 75.3% ุงุฒ ุชูุงู ููุงุฑุฏ ุฏุฑุณุช ูพุดโุจู ุดุฏูโุงูุฏ.<br>โ๏ธ ูุจุงุฏ ุชููุง ูุนุงุฑ ูุถุงูุช ุจุงุดุฏ โ ฺูู ุฏุงุฏูโูุง ูุงูุชุนุงุฏู ูุณุชูุฏ (65% ุณุงูู). ูุฏู ูโุชููู ููุท ุจุง ฺฏูุชู *"ููู ุณุงููโุงูุฏ"* ุจู Accuracy โ 0.65 ุจุฑุณู! |
| **Precision** | `0.618` | ููุช ูุฏู ูโฺฏูุฏ *"ุฏุงุฑุฏ ุฏุงุจุช"*, ููุท ุฏุฑ **61.8% ููุงุฑุฏ** ุฏุฑุณุช ุงุณุช.<br>๐ด ุนู **38.2% ุงุฒ ููุงุฑุฏ ูุซุจุชุ ุงุดุชุจุงู (False Positive)** ูุณุชูุฏ โ ุงูุฑุงุฏ ุณุงูู ุฑุง ุจูุงุฑ ุชุดุฎุต ุฏุงุฏู. ุฏุฑ ุนูู: ุขุฒูุงุดโูุง ุงุถุงูุ ุงุถุทุฑุงุจุ ูุฒูู. |
| **Recall (Sensitivity)** | `0.778` | ุงุฒ ููู ุจูุงุฑุงู ูุงูุนุ **77.8%** ุฑุง ุดูุงุณุง ฺฉุฑุฏู.<br>๐ข ุงู ุนุฏุฏ **ูุณุจุชุงู ุฎูุจ** ุงุณุช โ ุนู ููุท **22.2% ุงุฒ ุจูุงุฑุงู (12 ููุฑ)** ุงุฒ ุฏุณุช ุฑูุชูโุงูุฏ (False Negative). ุฏุฑ ูพุฒุดฺฉุ ุงู ููุฏุงุฑ ูุนูููุงู ูุงุจู ูุจูู ุงุณุชุ ูู ูุฏู ุจุงุฏ >0.85 ุง ุญุช >0.9 ุจุงุดุฏ. |
| **F1-Score** | `0.689` | ูุงูฺฏู ูุงุฑูููฺฉ Precision ู Recall.<br>๐ก ุนุฏุฏ **ูุชูุณุท** โ ูุดุงู ูโุฏูุฏ ูุฏู ุฏุฑ ุชุนุงุฏู ุจู ุฏูุช ู ุญุณุงุณุช **ุถุนู ุฏุงุฑุฏ**. ุจุฑุง ูุณุงุฆู ุญุณุงุณ ูพุฒุดฺฉุ F1 > 0.75 ุชุฑุฌุญ ุฏุงุฏู ูโุดูุฏ. |
| **Specificity (TNR)** | `0.740` | ุงุฒ ููู ุงูุฑุงุฏ ุณุงูู ูุงูุนุ **74%** ุฑุง ุฏุฑุณุช ุชุดุฎุต ุฏุงุฏู.<br>๐ ุนู **26% ุงุฒ ุงูุฑุงุฏ ุณุงูู (26 ููุฑ)** ุงุดุชุจุงู ุจูุงุฑ ฺฏุฑูุชู ุดุฏูโุงูุฏ โ ููุงู FPูุง. |
| **NPV** | `0.860` | ููุช ูุฏู ูโฺฏูุฏ *"ูุฏุงุฑุฏ ุฏุงุจุช"*, ุฏุฑ **86% ููุงุฑุฏ** ุฏุฑุณุช ุงุณุช.<br>๐ข ุงู ุนุฏุฏ **ุฎูุจ** ุงุณุช โ ุนู ุงฺฏุฑ ูพุงู *"ุณุงูู ูุณุชุฏ"* ุฏุงุฏุ ุงุญุชูุงูุงู ูุงูุนุงู ุณุงูู ุงุณุช. ุจุฑุง ุขุฑุงูุด ุจูุงุฑ ููู ุงุณุช. |
| **ROC-AUC** | `0.810` | ุชูุงูุง ฺฉู ูุฏู ุฏุฑ ุชูุงุฒ ุจู ฺฉูุงุณโูุง.<br>๐ข **ุจุงูุงุชุฑ ุงุฒ 0.8 = ุฎูุจ**. ูุดุงู ูโุฏูุฏ ูุฏู ุจูุชุฑ ุงุฒ ุญุฏุณ ุชุตุงุฏู ุนูู ูโฺฉูุฏ. |

> ๐ก **ูฺฉุชู ฺฉูุฏ**:  
> ุฏุฑ ฺฉุงุฑุจุฑุฏูุง ูพุฒุดฺฉุ **ฺฉุงูุด False Negative (ุงูุฒุงุด Recall)** ุงูููุช ุจุงูุงุชุฑ ูุณุจุช ุจู ฺฉุงูุด False Positive ุฏุงุฑุฏ โ ฺูู ุงุฒ ุฏุณุช ุฏุงุฏู ฺฉ ุจูุงุฑ (ุนุฏู ุชุดุฎุต ุฏุงุจุช) ูพุงูุฏูุง ุฌุฏโุชุฑ ูุณุจุช ุจู ุชุดุฎุต ุงุดุชุจุงู ฺฉ ูุฑุฏ ุณุงูู ุฏุงุฑุฏ.

## ุจุฎุด 15 ุชุตูุฑ ุนููฺฉุฑุฏ ููุง SVM ุฑู ฺฉูุงุณ ูุง ุจุง ุงุฌุงุฏ ูุฑุฒ ูุง

```
# ============================================================================
#  CLEAN SVM DECISION BOUNDARY VISUALIZATION (PCA - FULL & FIXED)
# ============================================================================

from sklearn.decomposition import PCA

print("\n" + "="*60)
print("SVM DECISION BOUNDARY VISUALIZATION (PCA)")
print("="*60)

# 1. PCA to 2D (visualization only)
pca = PCA(n_components=2, random_state=42)
X_pca = pca.fit_transform(X_train_scaled)

# 2. Train SVM on PCA data

svm_vis = SVC(
    kernel=best_svm.kernel,
    C=best_svm.C,
    gamma=best_svm.gamma,
    class_weight='balanced'
)
svm_vis.fit(X_pca, y_train)


# 3. Create mesh grid
x_min, x_max = X_pca[:, 0].min() - 1, X_pca[:, 0].max() + 1
y_min, y_max = X_pca[:, 1].min() - 1, X_pca[:, 1].max() + 1

xx, yy = np.meshgrid(
    np.linspace(x_min, x_max, 500),
    np.linspace(y_min, y_max, 500)
)

# 4. Decision function values
Z = svm_vis.decision_function(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

# 5. Plot
plt.figure(figsize=(10, 8))

# Decision boundary & margins
plt.contour(
    xx, yy, Z,
    levels=[-1, 0, 1],
    linestyles=['--', '-', '--'],
    linewidths=[1.2, 2.5, 1.2],
    colors='black'
)

# Classes
plt.scatter(
    X_pca[y_train == 0, 0],
    X_pca[y_train == 0, 1],
    c='royalblue',
    edgecolor='k',
    s=50,
    alpha=0.7,
    label='No Diabetes'
)

plt.scatter(
    X_pca[y_train == 1, 0],
    X_pca[y_train == 1, 1],
    c='crimson',
    edgecolor='k',
    s=50,
    alpha=0.7,
    label='Has Diabetes'
)

# Support vectors
plt.scatter(
    svm_vis.support_vectors_[:, 0],
    svm_vis.support_vectors_[:, 1],
    s=120,
    facecolors='none',
    edgecolors='black',
    linewidths=2,
    label='Support Vectors'
)

# Labels
plt.xlabel('PCA Component 1', fontsize=12)
plt.ylabel('PCA Component 2', fontsize=12)
plt.title(
    'SVM Decision Boundary with Support Vectors\n(PCA Projection - Visualization Only)',
    fontsize=14,
    fontweight='bold'
)

plt.legend(loc='upper left', fontsize=11, frameon=True)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

## output:
<img width="989" height="790" alt="image" src="https://github.com/user-attachments/assets/b23f2a39-5d79-4b5a-8d94-45bbd2346ce4" />


## ๐งญ ุนูุงุตุฑ ูููุฏุงุฑ

| ุนูุตุฑ | ุชูุถุญ |
|------|--------|
| **ูุญูุฑ X**: `PCA Component 1` | ูุคููู ุงุตู ุงูู โ ุญุงู ุจุดุชุฑู ูุงุฑุงูุณ ุฏุงุฏูโูุง |
| **ูุญูุฑ Y**: `PCA Component 2` | ูุคููู ุงุตู ุฏูู โ ุญุงู ุฏููู ุจุดุชุฑู ูุงุฑุงูุณ |
| **ููุงุท ุขุจ (No Diabetes)** | ูููููโูุง ูุงูุน ุจุฏูู ุฏุงุจุช |
| **ููุงุท ูุฑูุฒ (Has Diabetes)** | ูููููโูุง ูุงูุน ุจุง ุฏุงุจุช |
| **ุฏุงุฑูโูุง ูุดฺฉ ุจุง ุญุงุดู ุณูุฏ (Support Vectors)** | ูููููโูุง ฺฉู ูุฑุฒ ุชุตููโฺฏุฑ ุฑู ุขูโูุง ูุชฺฉ ุงุณุช โ ูููโุชุฑู ููุงุท ุจุฑุง ุชุดฺฉู ูุฑุฒ |
| **ุฎุท ุณุงู ููุญู (Decision Boundary)** | ูุฑุฒ ฺฉู ูุฏู SVM ุจุฑุง ุฌุฏุง ฺฉุฑุฏู ุฏู ฺฉูุงุณ ุงุณุชูุงุฏู ูโฺฉูุฏ |
| **ุฎุท ฺู ุณุงู (Margin)** | ุญุงุดู (Margin) ุญูู ูุฑุฒ ุชุตููโฺฏุฑ โ ูุงุตูู ุจู ูุฑุฒ ู ูุฒุฏฺฉโุชุฑู ููุงุท ุงุฒ ูุฑ ฺฉูุงุณ |


ุชูุณุฑ ู ุชุญูู 

โ ููุงุท ููุช:
ูุฑุฒ ุชุตููโฺฏุฑ ุบุฑุฎุท ุงุณุช โ ุนู ูุฏู ุงุฒ ฺฉ ฺฉุฑูู ุบุฑุฎุท (ูุซู RBF ุง Polynomial) ุงุณุชูุงุฏู ฺฉุฑุฏู โ ฺฉู ุจุฑุง ุฏุงุฏูโูุง ูพฺุฏู ูุซู ุฏุงุจุช ููุงุณุจ ุงุณุช.
ุจุฑุฏุงุฑูุง ูพุดุชุจุงู (Support Vectors) ุฏุฑ ุงุทุฑุงู ูุฑุฒ ุฌูุน ุดุฏูโุงูุฏ โ ูุดุงูโุฏููุฏู ุงู ุงุณุช ฺฉู ูุฏู ุฑู ููุงุท ูุฑุฒ ุชูุฑฺฉุฒ ุฏุงุฑุฏ.
ุชุนุฏุงุฏ ุฒุงุฏ ุงุฒ ููุงุท ูููพูุดุงู ุฏุงุฑูุฏ โ ฺฉู ุจุง ุชุญูู ูุจู (Probability Distribution) ููุฎูุงู ุฏุงุฑุฏ โ ุนู ูุฏู ููโุชูุงูุฏ ุฏู ฺฉูุงุณ ุฑุง ฺฉุงููุงู ุงุฒ ูู ุฌุฏุง ฺฉูุฏ.
โ๏ธ ููุงุท ุถุนู / ฺุงูุดโูุง:
ูููพูุดุงู ุฒุงุฏ ุจู ุฏู ฺฉูุงุณ โ ุนู ููุงุท ุขุจ ู ูุฑูุฒ ุฎู ุจู ูู ูุฒุฏฺฉ ูุณุชูุฏ โ ุงู ููุงู ุฏูู ุฎุทุงูุง ุทุจููโุจูุฏ (FP ู FN) ุงุณุช.
ูุฑุฒ ุชุตููโฺฏุฑ ุฏุฑ ููุงุทู ฺฺฏุงู โ ุนู ูุฏู ุฏุฑ ููุงุทู ฺฉู ุฏุงุฏูโูุง ุฒุงุฏ ูุณุชูุฏุ ูุฑุฒ ุฑุง ูโฺฉุดุฏ โ ุงูุง ุฏุฑ ููุงุทู ฺฉูโฺฺฏุงูุ ููฺฉูู ุฏูุช ฺฉูุชุฑ ุฏุงุดุชู ุจุงุดู.
ุชุตูุฑ ููุท ุจุฑุง ุจุตุฑโุณุงุฒ ุงุณุช โ ฺูู PCA ููุท ุญุฏูุฏ 50-70% ูุงุฑุงูุณ ุฏุงุฏูโูุง ุฑุง ุญูุธ ูโฺฉูุฏ โ ุจูุงุจุฑุงู ููโุชูุงู ุงุฒ ุงู ูููุฏุงุฑ ุจุฑุง ุชุญูู ุฏูู ุงุณุชูุงุฏู ฺฉุฑุฏ.


 ูพุดููุงุฏุงุช :
1. ุจุฑุฑุณ Overfitting:
ุงฺฏุฑ ูุฏู ุฑู ุฏุงุฏูโูุง ุขููุฒุด Accuracy ุจุงูุง ุฏุงุฑุฏ ุงูุง ุฑู ุชุณุช ูพุงู ุงุณุช โ ููฺฉูู Overfit ุดุฏู ุจุงุดุฏ.
ูโุชูู ุงุฒ Validation Curve ุง Learning Curve ุงุณุชูุงุฏู ฺฉู ุชุง ุงู ููุถูุน ุฑู ุจุฑุฑุณ ฺฉู.
2. ุงุณุชูุงุฏู ุงุฒ ูุฏูโูุง ุฏฺฏุฑ:
ูุฏูโูุง ูุซู Random Forest ุง XGBoost ููฺฉูู ุฏุฑ ูุถุง ูฺฺฏโูุง ุจูุชุฑ ุนูู ฺฉููุฏ โ ฺูู ูโุชููู ุงูฺฏููุง ุบุฑุฎุท ุฑุง ุจูุชุฑ ุชุดุฎุต ุจุฏู.
3. ุงูุฒูุฏู ูฺฺฏโูุง ุชุนุงูู:
ูุซูุงู Glucose ร BMI ุง Age ร Pregnancies โ ฺฉู ููฺฉูู ุฏุฑ ูุถุง PCA ุจูุชุฑ ุฌุฏุง ุดููุฏ.
